<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Keynote | Timbre 2023</title><link>https://timbre-conference.github.io/timbre2023/tag/keynote/</link><atom:link href="https://timbre-conference.github.io/timbre2023/tag/keynote/index.xml" rel="self" type="application/rss+xml"/><description>Keynote</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><image><url>https://timbre-conference.github.io/timbre2023/media/icon_hu7323a42ed76de0e4f05a1335f0d314af_7405_512x512_fill_lanczos_center_3.png</url><title>Keynote</title><link>https://timbre-conference.github.io/timbre2023/tag/keynote/</link></image><item><title>Keynote 1: P. A. Tremblay</title><link>https://timbre-conference.github.io/timbre2023/session/tue/keynote-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://timbre-conference.github.io/timbre2023/session/tue/keynote-1/</guid><description>&lt;br>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Day:&lt;/strong>&lt;/td>
&lt;td>Tuesday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Time:&lt;/strong>&lt;/td>
&lt;td>12:15 - 13:00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Location:&lt;/strong>&lt;/td>
&lt;td>McGill University&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Room:&lt;/strong>&lt;/td>
&lt;td>Tanna Schulich Hall&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="speaker">Speaker&lt;/h2>
&lt;!-- - [Pierre Alexandre Tremblay](/timbre2023/people/pierre-alexandre-tremblay/) -->
&lt;h2 id="title">Title&lt;/h2>
&lt;ul>
&lt;li>&amp;ldquo;Beyond cohabitation: towards a rich interdisciplinarity in music-technology research&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h2 id="description">Description&lt;/h2>
&lt;p>Too often, interdisciplinarity is considered a hurdle in a grant application, a box to tick. Even when the intention is genuine, rarely music technology projects go beyond one discipline servicing the other. What happens when we go candidly yet rigorously beyond cohabitation, from multi- to interdisciplinarity; from science-as-research to a plurality of research practices; from a service model to one that embraces the complex interrelation between disciplines across their porous barriers? Music technology research has a great potential to be truly interdisciplinary, not as add-on nor an in-between, but as a field in itself, a fluid third stream. Such endeavour is possible only if we go beyond a mere cohabitation of the parent disciplines, dissolving taxonomies, challenging epistemic commitments, towards hybridizing as a way to evolve. We hope to provoke a rich discussion during follow-up interactive sessions, in order to generate constructive ways forward for rich interdisciplinary music technology research projects.&lt;/p>
&lt;p>This talk will propose a forum to go to the roots of the next big questions of our respective fields, and embrace the richness and complexities of their agonistic diversity. We hope to generate constructive ways forward for rich interdisciplinary music technology research projects.&lt;/p></description></item><item><title>Keynote 2: Alain Fleisher</title><link>https://timbre-conference.github.io/timbre2023/session/wed/keynote-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://timbre-conference.github.io/timbre2023/session/wed/keynote-2/</guid><description>&lt;br>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Day:&lt;/strong>&lt;/td>
&lt;td>Wednesday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Time:&lt;/strong>&lt;/td>
&lt;td>10:15 - 11:00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Location:&lt;/strong>&lt;/td>
&lt;td>Université de Montréal&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Room:&lt;/strong>&lt;/td>
&lt;td>B421&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="speaker">Speaker&lt;/h2>
&lt;!-- - [Alain Fleisher](/timbre2023/people/alain-fleischer/) -->
&lt;h2 id="title">Title&lt;/h2>
&lt;ul>
&lt;li>&amp;ldquo;Transfert de formes / Transfert de sens (Transfer of forms, transfer of meaning)&amp;rdquo; &lt;!-- need English translation -->&lt;/li>
&lt;/ul>
&lt;h2 id="description----need-english-translation---">Description &lt;!-- need English translation -->&lt;/h2>
&lt;p>Je m’intéresse depuis quelque temps à la question du transfert des formes, du monde sonore vers le monde visuel, du bidimensionnel au tridimensionnel, de l’analogique au numérique… et vice versa.&lt;/p>
&lt;p>On sait, depuis que le cinéma est parlant, que la bande sonore d’un film devient un signal optique couché sur un côté de la bande-image. Ce fut d’abord un système de traits préfigurant les codes barre, et puis s’est généralisée la forme d’une ondulation (wave form) noire sur fond blanc pour les films en noir et blanc, ou bleue sur fond jaune pour les films en couleur. Ainsi le son devient une image, et les techniciens du cinéma avaient l’habitude d’évaluer le report optique d’une bande sonore selon de critères photographiques : piqué, netteté, grain, contraste, etc.&lt;/p>
&lt;p>A partir de là, j’ai expérimenté le report de cette ondulation, de cette modulation, sur diverses sortes d’images, en multipliant les transferts d’un support sur l’autre, soit par les moyens d’interface numériques, soit par de simples calques ou empreintes analogiques faits à la main. Ces recherches m’ont conduit, après avoir fait voyager un support sonore (une phrase), par des reports successifs, à essayer de la lire à nouveau pour constater si le message d’origine s’était conservé, avec éventuellement quelles altérations, quels accidents, survenus pendant le long voyage à travers différents espaces. J’ai été ainsi amené à faire réaliser des lecteurs capables de déchiffrer le message sonore par lecture d’une image contenant sa forme visuelle plusieurs fois reportée. Le résultat était concluant avec la restitution, parfaitement identifiable, de la phrase d’origine.&lt;/p>
&lt;p>Dans le prolongement de ces expériences, mes nouvelles recherches portent sur la transformation de la parole chantée et de la musique en images, c’est-à-dire de signaux sonores en signaux optiques. Avec toujours le même objectif de transférer successivement le signal, la modulation (la wave form), d’un support sur l’autre, en passant par des supports traditionnels comme le disque vinyle, par des CD numériques, par des empreintes sur différentes matières, par des transcriptions de l’ordre du dessin. L’objectif sera à nouveau de constater ce que devient une forme musicale (y compris le chant), après être passée par ces transferts successifs.&lt;/p>
&lt;p>L’exposé de mes recherches pourra être illustré par des images, par la présentation des instruments de déchiffrage, et par des enregistrements.&lt;/p></description></item><item><title>Keynote 3: I. Choi &amp; R. Bargar</title><link>https://timbre-conference.github.io/timbre2023/session/wed/keynote-3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://timbre-conference.github.io/timbre2023/session/wed/keynote-3/</guid><description>&lt;br>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Day:&lt;/strong>&lt;/td>
&lt;td>Wednesday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Time:&lt;/strong>&lt;/td>
&lt;td>14:00 - 14:45&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Location:&lt;/strong>&lt;/td>
&lt;td>Université de Montréal&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Room:&lt;/strong>&lt;/td>
&lt;td>B421&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="speakers">Speakers&lt;/h2>
&lt;!-- - [Insook Choi](/timbre2023/people/insook-choi/) -->
&lt;!-- - [Robin Bargar](/timbre2023/people/robin-bargar/) -->
&lt;h2 id="title">Title&lt;/h2>
&lt;ul>
&lt;li>&amp;ldquo;Where to Encode Musical Information&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h2 id="description">Description&lt;/h2>
&lt;p>Music-making and listener engagement are emerging in new modalities, sites, and mediums, creating an imperative to re-examine cultural and personal channels for musical experiences. Musical information and its encoding can provide a consistent perspective across practices, historical periods, and cultures, and this perspective may support a concerned community of practice.&lt;/p>
&lt;p>Sites and mediums are two salient factors, and their characteristics affect listeners’ modality of engagement. In modern epoch marked with a certain technological capacity, the distributed, mobile, situated, and participatory are among other possible characteristics that transform the definition of sites and medium. For the sustainability of professional musical practice, we may reconsider the social contract of composer, performer, and audience by examining what changes in perspectives are required concerning musical information and its encoding.&lt;/p>
&lt;p>Musical experience is a sensorial phenomenon that is highly subjected to variance based on a modality of engagement. Recent neuroscientific findings indicate sustained experience changes neural function. This means that the kind of musical experience we may expect is loosely presumed based on prior experiences, with a degree of confidence, within which the modality of engagement is also expected. Towards a sustainable musical practice, the question where to go from here can be shortcut by questioning where to encode musical information. Since the paradigm of Western common practice was historically effective, we may still unwittingly subsume contemporary practice to that paradigm, regardless of interactive music or DSP for new instruments. However, the history of the common practice was about the process of musical discourse regarding where to encode musical information, the process of acculturation. Perhaps, we have been too much focusing on music as a product of culture or creative individuals, not enough on musical interaction.&lt;/p>
&lt;p>For musical interaction, ‘where to encode’ comes as a novel question that future music research should address to elucidate the intrinsically multimodal nature of music and its impact on sociocultural human perception, cognition, and functional organization of the human brain. In multimedia context, musical interaction can also function as a central motivation for integrating other media and enabling participatory engagement. This keynote will address the motivation, aims, and methods of musical interaction research as well as its conceptual framework with a set of enabling dimensions for situating potential values in the relationship between people, music, and technologies. For this research agenda, we will discuss an interdisciplinary requirement and collaborative landscape to move us forward with a formative process of defining a locus with emerging criteria.&lt;/p></description></item><item><title>Keynote 4: Sidney Fels</title><link>https://timbre-conference.github.io/timbre2023/session/thu/keynote-4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://timbre-conference.github.io/timbre2023/session/thu/keynote-4/</guid><description>&lt;br>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Day:&lt;/strong>&lt;/td>
&lt;td>Thursday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Time:&lt;/strong>&lt;/td>
&lt;td>10:00 - 10:45&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Location:&lt;/strong>&lt;/td>
&lt;td>McGill University&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Room:&lt;/strong>&lt;/td>
&lt;td>Tanna Schulich Hall&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="speaker">Speaker&lt;/h2>
&lt;!-- - [Sidney Fels](/timbre2023/people/sidney-fels/) -->
&lt;h2 id="title">Title&lt;/h2>
&lt;ul>
&lt;li>&amp;ldquo;Breaking the Brain to Sound Barrier: Leveraging the Mind-Body Continuum for Musical Expression&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;h2 id="description">Description&lt;/h2>
&lt;p>Working with the idea that the mind and body form a continuum of thought to control that learns to incorporate biomechanics and environmental constraints with perceptual ones to achieve players goals, we are looking for ways to create new adaptive mechanisms for New Interfaces for Musical Expression (NIMEs) that help to reduce information demands on players while at the same time increasing information throughput for more expressive interfaces. I’ll present some of efforts towards brain to speech interfaces as well as some abstract work that explores how we can build adaptive NIMEs.&lt;/p></description></item><item><title>Keynote 5: Louis-Xavier Buffoni</title><link>https://timbre-conference.github.io/timbre2023/session/thu/keynote-5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://timbre-conference.github.io/timbre2023/session/thu/keynote-5/</guid><description>&lt;br>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Day:&lt;/strong>&lt;/td>
&lt;td>Thursday&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Time:&lt;/strong>&lt;/td>
&lt;td>14:15 - 15:00&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Location:&lt;/strong>&lt;/td>
&lt;td>McGill University&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Room:&lt;/strong>&lt;/td>
&lt;td>Tanna Schulich Hall&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="speaker">Speaker&lt;/h2>
&lt;!-- - [Louis-Xavier Buffoni](/timbre2023/people/louis-xavier-buffoni/) -->
&lt;h2 id="title">Title&lt;/h2>
&lt;ul>
&lt;li>&amp;ldquo;The Future of Interactive Audio&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;!--
## Description
Minim eiusmod velit dolore enim. Dolor aliquip esse ea culpa mollit consequat aute exercitation mollit officia sint nulla reprehenderit elit. Sunt tempor incididunt qui sunt ipsum. Lorem anim veniam nisi excepteur. Veniam ullamco aliquip incididunt Lorem magna laboris et sit nulla aliqua.
--></description></item></channel></rss>